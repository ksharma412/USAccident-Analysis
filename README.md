# USAccident-Analysis: Identifying key factors causing severe accidents in United States
Data import, data cleaning, exploratory data analysis, and data modelling

## Introduction 
- In the world of today where data is being used to derive useful insights in all spheres, I wanted to use the power of data to analyze various aspects related to a lethal problem that the world, especially the United States of America is facing. Thus, the name of the dataset I have analyzed is “US Accidents”. I noted that the country is one of the busiest countries in terms of road traffic with nearly 280 million vehicles in operation and more than 227.5 million drivers holding a valid driving license. Road accidents have become very common these days. In the USA, over 40k people die in road accidents each year, and 3 million get injured. Road crashes cost the country around $230 billion per year or an average of $ 822 per person.

## About the dataset
- As a part of my analysis, I have focused on the data of accidents in the United States of America and have considered and have taken into account the data related to all the 50 states. The dataset contains data of all the accidents in 50 states of the US. The data is collected using multiple API’s that provide streaming traffic incident data. It has 47 variables and 1048576 observations. I have information about each observation which include the place of the accident, the time of the accident, the temperature at the place, the humidity of the place, the severity of the accident, the time of the day, the wind speed, the weather prediction for that day and many more.

- I have picked this data as it has almost all type of data such as time, date, numerical values, strings, floating type integers, Boolean values etc. and I wanted to experiment and learn data analysis on datasets which are much like those in the real world. The size of the dataset is also huge, and it has given me an opportunity to dive deep into the data and understand the basic concepts of data cleaning, analysis, and modelling in a much better way. This project has given me an opportunity to learn how to clean data properly while working with different types of data; learn how to do EDA and then create models. I have covered linear regression and random forest in this project. 

<img width="350" alt="image" src="https://user-images.githubusercontent.com/92357231/165868606-d421682c-86b7-42b3-962e-ae7363a69a50.png">

